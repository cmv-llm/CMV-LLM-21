# CMV-LLM: China's mainstream values large language model

## Overview

Existing large language models often exhibit significant value bias, making them misaligned with the mainstream values of their respective nations. To address this issue, we explore how to align a large language model's ideological stance with their national mainstream values. We introduce CMV-LLM, a model that aligns with China's mainstream values, by carefully curating large-scale Chinese datasets and fine-tuning. To validate its effectiveness, we evaluate the model using a national values assessment dataset, comparing it with several popular LLMs. 

The results demonstrate that our CMV-LLM generates content more accurately reflecting China's mainstream values, providing a novel approach and practical insights for building large language models aligned with national stances. 


## Model Access

The CMV-LLM model is available on Hugging Face for easy access and deployment:

- **Model on Hugging Face:** [CMV-LLM on Hugging Face](https://huggingface.co/gotime/CMV-LLM)
- **Dataset on Hugging Face:** [CMV-LLM-Dataset on Hugging Face](https://huggingface.co/datasets/gotime/CMV-LLM-Dataset)

## Potential Risks and Warnings

- **Bias and Harmful Content:** While CMV-LLM aims to align with national values, users should be aware that the training datasets and model may still contain biases or harmful content. Caution should be exercised when using the model in sensitive applications.
- **Example Usage:** The examples provided in this repository may contain ideological or cultural perspectives that reflect national mainstream views. These should be considered in the context of their intended application.
